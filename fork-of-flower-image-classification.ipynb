{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2431805,"sourceType":"datasetVersion","datasetId":8782}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing the necessary libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport random\nimport numpy as np\nimport seaborn as sns\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans, DBSCAN\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.metrics import silhouette_score, adjusted_rand_score, homogeneity_score, v_measure_score\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n","metadata":{"execution":{"iopub.status.busy":"2024-09-19T14:15:07.12418Z","iopub.execute_input":"2024-09-19T14:15:07.124687Z","iopub.status.idle":"2024-09-19T14:15:25.734952Z","shell.execute_reply.started":"2024-09-19T14:15:07.124628Z","shell.execute_reply":"2024-09-19T14:15:25.733828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analyzing the Data","metadata":{}},{"cell_type":"markdown","source":"Let's analyze the dataset I choose for my image classification project.","metadata":{}},{"cell_type":"code","source":"def total_dataset_size(directory):\n    total_images = 0\n    total_size = 0\n    \n    for label in os.listdir(directory):\n        label_dir = os.path.join(directory, label)\n        if os.path.isdir(label_dir):\n            image_files = os.listdir(label_dir)\n            total_images += len(image_files)\n            total_size += sum(os.path.getsize(os.path.join(label_dir, img)) for img in image_files)\n    \n    total_size_MB = total_size / (1024 * 1024)  # Convert bytes to MB\n    return total_images, total_size_MB\n\ndef print_total_dataset_size(total_images, total_size_MB):\n    print(f\"Total Number of Images: {total_images}\")\n    print(f\"Total Dataset Size: {total_size_MB:.2f} MB\")\n\n# Usage\ntotal_images, total_size_MB = total_dataset_size('/kaggle/input/flowers-recognition/flowers/')\nprint_total_dataset_size(total_images, total_size_MB)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-19T14:15:25.736563Z","iopub.execute_input":"2024-09-19T14:15:25.73746Z","iopub.status.idle":"2024-09-19T14:15:27.29867Z","shell.execute_reply.started":"2024-09-19T14:15:25.737401Z","shell.execute_reply":"2024-09-19T14:15:27.297397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This dataset consists of 4,317 images of flowers, including rose, dandelion, sunflower, daisy, and tulip. The dataset size is 228 MB, which is relatively small but manageable compared to larger datasets, and it allows for faster experimentation.","metadata":{}},{"cell_type":"code","source":"def display_images(directory, num_images=5, preprocess=False):\n    labels = [label for label in os.listdir(directory) if os.path.isdir(os.path.join(directory, label))]\n    fig, axes = plt.subplots(len(labels), num_images, figsize=(15, len(labels) * 3))\n    fig.suptitle(f\"Images from {directory.split('/')[-1]}\", fontsize=16)\n    \n    for i, label in enumerate(labels):\n        label_dir = os.path.join(directory, label)\n        image_files = os.listdir(label_dir)\n        random.shuffle(image_files)\n        for j in range(num_images):\n            image_path = os.path.join(label_dir, image_files[j])\n            if preprocess:\n                img = preprocess_image(image_path)\n            else:\n                img = cv2.imread(image_path)\n                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            if img is not None:\n                axes[i, j].imshow(img)\n            else:\n                axes[i, j].imshow(np.ones((128, 128, 3)))  # Display a blank image if preprocessing fails\n            axes[i, j].set_title(f\"{label} Image {j+1}\")\n            axes[i, j].axis('off')\n    \n    plt.tight_layout()\n    plt.show()\n    \ndisplay_images('/kaggle/input/flowers-recognition/flowers/')","metadata":{"execution":{"iopub.status.busy":"2024-09-19T14:15:27.300088Z","iopub.execute_input":"2024-09-19T14:15:27.300433Z","iopub.status.idle":"2024-09-19T14:15:31.650446Z","shell.execute_reply.started":"2024-09-19T14:15:27.300396Z","shell.execute_reply":"2024-09-19T14:15:31.648385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here are the images from the five classes of the dataset. As you can see, they are of different sizes and are colorful.","metadata":{}},{"cell_type":"code","source":"def plot_class_distribution(directory):\n    labels = [label for label in os.listdir(directory) if os.path.isdir(os.path.join(directory, label))]\n    counts = [len(os.listdir(os.path.join(directory, label))) for label in labels]\n    \n    plt.figure(figsize=(10, 6))\n    plt.bar(labels, counts, color='skyblue')\n    plt.xlabel('Class')\n    plt.ylabel('Number of Images')\n    plt.title('Class Distribution in Dataset')\n    plt.xticks(rotation=45)\n    plt.show()\n\nplot_class_distribution('/kaggle/input/flowers-recognition/flowers/')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-19T14:15:31.654688Z","iopub.execute_input":"2024-09-19T14:15:31.655173Z","iopub.status.idle":"2024-09-19T14:15:31.965902Z","shell.execute_reply.started":"2024-09-19T14:15:31.655128Z","shell.execute_reply":"2024-09-19T14:15:31.963929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In this graph, we can see that all of the classes are distributed nearly equally, so in the next steps of my project, I will not need to implement techniques like data augmentation for my dataset.","metadata":{}},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"def preprocess_image(image_path, img_size=(128, 128)):\n    img = cv2.imread(image_path)\n    if img is None:\n        return None\n    img_resized = cv2.resize(img, img_size)\n    img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)\n    img_normalized = img_rgb / 255.0\n    return img_normalized\n\ndisplay_images('/kaggle/input/flowers-recognition/flowers/', preprocess=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-19T14:15:31.968457Z","iopub.execute_input":"2024-09-19T14:15:31.969278Z","iopub.status.idle":"2024-09-19T14:15:36.30281Z","shell.execute_reply.started":"2024-09-19T14:15:31.969209Z","shell.execute_reply":"2024-09-19T14:15:36.301481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" The preprocess_image function specifically handles resizing, color conversion, and normalization of images. This preprocessing step is crucial for preparing images to be fed into a machine learning model, ensuring consistency in image dimensions and pixel value. Here are the images after preprocessing. Seeing these images will help us understand what the function does better.","metadata":{}},{"cell_type":"code","source":"def load_images(directory, img_size=(128, 128)):\n    X = []\n    y = []\n    \n    for label in os.listdir(directory):\n        label_dir = os.path.join(directory, label)\n        \n        if os.path.isdir(label_dir):\n            for filename in os.listdir(label_dir):\n                image_path = os.path.join(label_dir, filename)\n                \n                # Preprocess the image\n                img_preprocessed = preprocess_image(image_path, img_size)\n                \n                if img_preprocessed is not None:\n                    X.append(img_preprocessed)\n                    y.append(label)\n    \n    return np.array(X), np.array(y)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-19T14:15:36.304362Z","iopub.execute_input":"2024-09-19T14:15:36.304766Z","iopub.status.idle":"2024-09-19T14:15:36.316889Z","shell.execute_reply.started":"2024-09-19T14:15:36.304723Z","shell.execute_reply":"2024-09-19T14:15:36.315295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Splitting training and test dataset","metadata":{}},{"cell_type":"markdown","source":"Now it is time for splitting the dataset into two sets which are for training and testing. Training and test datasets will be used in supervised learning. ","metadata":{}},{"cell_type":"code","source":"# Load data\nX, y = load_images('/kaggle/input/flowers-recognition/flowers/')\n\n# Flatten images for K-Means\nX_flattened = X.reshape(X.shape[0], -1)\n\n# Convert string labels to integers\nlabel_encoder = LabelEncoder()\ny_int = label_encoder.fit_transform(y)\n\n# Split the data\nX_train, X_test, y_train, y_test = train_test_split(X, y_int, test_size=0.2, random_state=42, stratify=y_int)\n\n# Flatten the images for Rnadom Forest\nX_train_flattened = X_train.reshape(X_train.shape[0], -1)\nX_test_flattened = X_test.reshape(X_test.shape[0], -1)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-19T14:15:36.319326Z","iopub.execute_input":"2024-09-19T14:15:36.319736Z","iopub.status.idle":"2024-09-19T14:16:19.41983Z","shell.execute_reply.started":"2024-09-19T14:15:36.319692Z","shell.execute_reply":"2024-09-19T14:16:19.418288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In this code snippet, we can see that the data used for K-means and Random Forest are flattened. This is because both algorithms require the data to be in the form of feature vectors. By flattening the data, we convert multi-dimensional matrices into one-dimensional vectors, which allows the algorithms to process the data effectively.","metadata":{}},{"cell_type":"markdown","source":"# Choosing the Algorithms\n## Supervised\n### CNN","metadata":{}},{"cell_type":"markdown","source":"For this flower classification problem, I chose two unsupervised algorithms. The first one is CNN, which is quite popular for image-related projects.","metadata":{}},{"cell_type":"code","source":"def train_cnn_model(input_shape=(128, 128, 3), num_classes=5, X_train=None, y_train=None):\n    model = Sequential([\n        Input(shape=input_shape),\n        Conv2D(32, (3, 3), activation='relu', padding='same'),\n        MaxPooling2D(pool_size=(2, 2)),\n        Conv2D(64, (3, 3), activation='relu', padding='same'),\n        MaxPooling2D(pool_size=(2, 2)),\n        Conv2D(128, (3, 3), activation='relu', padding='same'),\n        MaxPooling2D(pool_size=(2, 2)),\n        Flatten(),\n        Dense(128, activation='relu'),\n        Dropout(0.5),\n        Dense(num_classes, activation='softmax')\n    ])\n    \n    model.compile(\n        optimizer='adam',\n        loss='sparse_categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    \n    model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2024-09-19T14:16:19.421618Z","iopub.execute_input":"2024-09-19T14:16:19.422073Z","iopub.status.idle":"2024-09-19T14:16:19.434722Z","shell.execute_reply.started":"2024-09-19T14:16:19.422011Z","shell.execute_reply":"2024-09-19T14:16:19.432661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here are the layers that I used for my model and their purposes:\n\n* **Input Layer:** Takes images of shape input_shape. \n* **Convolutional Layers:** Three convolutional layers (Conv2D) with increasing filter sizes (32, 64, and 128) and ReLU activation, each followed by a max pooling layer (MaxPooling2D) to reduce the spatial dimensions.\n* **Flatten Layer:** Converts the 2D feature maps into a 1D vector.\n* **Dense Layers:** Fully connected layers where the first dense layer has 128 units with ReLU activation, followed by a dropout layer with a rate of 0.5 to prevent overfitting.\n* **Output Layer:** A final dense layer with num_classes units and softmax activation to produce class probabilities.","metadata":{}},{"cell_type":"code","source":"# Train the CNN model\ncnn_model = train_cnn_model(X_train=X_train, y_train=y_train)\n\n# Predict the labels for the test set\ncnn_pred = cnn_model.predict(X_test)\ny_pred_cnn = np.argmax(cnn_pred, axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-09-19T14:16:19.436482Z","iopub.execute_input":"2024-09-19T14:16:19.436916Z","iopub.status.idle":"2024-09-19T14:26:41.028327Z","shell.execute_reply.started":"2024-09-19T14:16:19.436872Z","shell.execute_reply":"2024-09-19T14:26:41.027136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Random Forest","metadata":{}},{"cell_type":"markdown","source":"The second algorithm I chose is Random Forest. Random Forest is popular because of its ability to handle large datasets with high dimensionality. It operates by creating a multitude of decision trees during training and outputs the class that is the mode of the classes (for classification) or the mean prediction (for regression) of the individual trees.","metadata":{}},{"cell_type":"code","source":"def train_random_forest(X_train, y_train):\n    model = RandomForestClassifier(\n        n_estimators=500,          # Number of trees\n        max_depth=None,            # Depth of each tree\n        min_samples_split=2,       # Minimum number of samples required to split an internal node\n        min_samples_leaf=1,        # Minimum number of samples required to be at a leaf node\n        max_features='sqrt',       # Number of features to consider when looking for the best split\n        criterion='gini',          # Function to measure the quality of a split\n        random_state=42,           # Seed for random number generator\n        class_weight='balanced'    # Adjust weights inversely proportional to class frequencies\n    )\n    model.fit(X_train, y_train)\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-09-19T14:26:41.030029Z","iopub.execute_input":"2024-09-19T14:26:41.030485Z","iopub.status.idle":"2024-09-19T14:26:41.037765Z","shell.execute_reply.started":"2024-09-19T14:26:41.030441Z","shell.execute_reply":"2024-09-19T14:26:41.036538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here are the parameters I choosed for my model and their purposes:\n* **n_estimators=500:** Specifies 500 decision trees in the forest.\n* **max_depth=None:** Trees are allowed to grow until all leaves are pure or contain fewer than min_samples_split samples.\n* **min_samples_split=2:** A node must have at least 2 samples to be split.\n* **min_samples_leaf=1:** A leaf node must have at least 1 sample.\n* **max_features='sqrt':** Each tree considers the square root of the total number of features when looking for the best split.\n* **criterion='gini':** Uses the Gini impurity measure to evaluate the quality of splits.\n* **random_state=42:** Sets the seed for the random number generator for reproducibility.\n* **class_weight='balanced':** Adjusts the weights of classes inversely proportional to their frequencies to handle class imbalance.","metadata":{}},{"cell_type":"code","source":"# Train the Random Forest model\nmodel_rf = train_random_forest(X_train_flattened, y_train)\n\n# Predict the labels for the test set\ny_pred_rf = model_rf.predict(X_test_flattened)","metadata":{"execution":{"iopub.status.busy":"2024-09-19T14:26:41.03929Z","iopub.execute_input":"2024-09-19T14:26:41.039669Z","iopub.status.idle":"2024-09-19T14:31:36.363298Z","shell.execute_reply.started":"2024-09-19T14:26:41.039629Z","shell.execute_reply":"2024-09-19T14:31:36.361743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Unsupervised\n### K-means","metadata":{}},{"cell_type":"markdown","source":"For unsupervised learning, I chose K-Means, which is not typically preferred for image classification.","metadata":{}},{"cell_type":"code","source":"# Apply PCA\npca = PCA(n_components=50)\nX_pca = pca.fit_transform(X_flattened)\n\n# Perform K-Means clustering\nnum_clusters = len(np.unique(y))  # Set the number of clusters to the number of unique labels\nkmeans = KMeans(n_clusters=num_clusters, n_init=10, random_state=42)  # Explicitly set n_init\ny_pred_km = kmeans.fit_predict(X_pca)\n\n# Apply PCA on the test set\nX_test_pca = pca.transform(X_test_flattened)\n\n# Perform K-Means clustering on the test set\ny_pred_km_test = kmeans.predict(X_test_pca)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-19T14:31:36.364933Z","iopub.execute_input":"2024-09-19T14:31:36.365425Z","iopub.status.idle":"2024-09-19T14:31:59.615239Z","shell.execute_reply.started":"2024-09-19T14:31:36.365378Z","shell.execute_reply":"2024-09-19T14:31:59.61381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here are the explanation for the steps of unsupervised learning:\n\n* **Apply PCA:** Reduces the dimensionality of the flattened training data (X_flattened) to 50 principal components using PCA (Principal Component Analysis).\n\n* **Perform K-Means Clustering:**\n\nInitializes a K-Means clustering model with the number of clusters equal to the number of unique labels in y (which matches the number of classes).\nTrains the K-Means model on the PCA-transformed training data (X_pca) and predicts cluster labels (y_pred_km).\nApply PCA on the Test Set: Transforms the flattened test data (X_test_flattened) using the same PCA model to obtain its PCA representation (X_test_pca).\n\n* **Perform K-Means Clustering on the Test Set:**\n\nUses the trained K-Means model to predict cluster labels for the PCA-transformed test data (y_pred_km_test).","metadata":{}},{"cell_type":"code","source":"# Plot PCA components\nplt.figure(figsize=(12, 6))\n\n# Plot PCA results\nplt.subplot(1, 2, 1)\nplt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_int, cmap='viridis', marker='o', edgecolor='k', alpha=0.7)\nplt.colorbar(label='True Labels')\nplt.title('PCA - True Labels')\n\n# Plot K-Means clustering results\nplt.subplot(1, 2, 2)\nplt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_pred_km, cmap='viridis', marker='o', edgecolor='k', alpha=0.7)\nplt.colorbar(label='Cluster Labels')\nplt.title('PCA - K-Means Clustering')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-19T14:31:59.620417Z","iopub.execute_input":"2024-09-19T14:31:59.621371Z","iopub.status.idle":"2024-09-19T14:32:00.845779Z","shell.execute_reply.started":"2024-09-19T14:31:59.621318Z","shell.execute_reply":"2024-09-19T14:32:00.844307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"By these two graphs we can say that K-Means Clustering did not work well on the flower dataset. ","metadata":{}},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"markdown","source":"Here are the evaluation metrices and their explanations:\n### For supervised\n\n#### 1. **Accuracy**\n- **Definition**: The proportion of correctly classified instances (both true positives and true negatives) out of the total number of instances.\n- **Formula**: \n  \\[\n  \\text{Accuracy} = \\frac{\\text{True Positives} + \\text{True Negatives}}{\\text{Total Number of Instances}}\n  \\]\n- **Use Case**: Provides a general measure of how well the model performs overall, but can be misleading if classes are imbalanced.\n\n#### 2. **Precision**\n- **Definition**: The proportion of true positive instances out of all instances classified as positive.\n- **Formula**: \n  \\[\n  \\text{Precision} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Positives}}\n  \\]\n- **Use Case**: Useful when the cost of false positives is high. For instance, in spam detection, you want to minimize non-spam emails incorrectly classified as spam.\n\n#### 3. **Recall (Sensitivity or True Positive Rate)**\n- **Definition**: The proportion of true positive instances out of all actual positive instances.\n- **Formula**: \n  \\[\n  \\text{Recall} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Negatives}}\n  \\]\n- **Use Case**: Important when the cost of false negatives is high. For example, in medical diagnoses, you want to identify as many positive cases as possible, even if it means having some false positives.\n\n#### 4. **F1 Score**\n- **Definition**: The harmonic mean of precision and recall, providing a balance between them. It is useful when you need a single metric to evaluate a model's performance, especially with imbalanced datasets.\n- **Formula**: \n  \\[\n  \\text{F1 Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n  \\]\n- **Use Case**: Provides a better measure of performance when dealing with uneven class distributions. It balances precision and recall, making it useful in many practical situations.\n","metadata":{}},{"cell_type":"markdown","source":"### For unsupervised\n#### 1. **Silhouette Score**\n- **Definition**: Measures how similar an object is to its own cluster compared to other clusters. It evaluates both cohesion (how close the object is to other points in the same cluster) and separation (how far the object is from points in other clusters).\n- **Range**: -1 to +1. A score close to +1 indicates that the points are well clustered, while a score close to -1 indicates that the points might be incorrectly clustered.\n\n#### 2. **Homogeneity Score**\n- **Definition**: Measures how well each cluster contains only members of a single class. It quantifies how much the clusters match the true labels.\n- **Range**: 0 to 1. A score of 1 means that all clusters contain only members of a single class.\n\n#### 3. **V-Measure Score**\n- **Definition**: Measures the balance between homogeneity and completeness. It assesses how well the clusters match the true class labels by considering both how much of a class is found in a cluster (completeness) and how many clusters of a class there are (homogeneity).\n- **Range**: 0 to 1. A score of 1 means perfect balance between homogeneity and completeness.\n\n#### 4. **Adjusted Rand Index (ARI)**\n- **Definition**: Measures the similarity between two data clusterings by considering all pairs of points and how often they are clustered together or apart. It adjusts for chance grouping, providing a more accurate assessment of clustering quality.\n- **Range**: -1 to 1. A score of 1 indicates perfect agreement between clusterings, while a score close to 0 indicates random clustering. Negative values indicate less than expected agreement by chance.\n","metadata":{}},{"cell_type":"code","source":"def evaluate(y_true, y_pred):\n    accuracy = accuracy_score(y_true, y_pred)\n    precision = precision_score(y_true, y_pred, average='weighted')\n    recall = recall_score(y_true, y_pred, average='weighted')\n    f1 = f1_score(y_true, y_pred, average='weighted')\n    \n    print(f\"Test Accuracy: {accuracy:.4f}\")\n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall: {recall:.4f}\")\n    print(f\"F1 Score: {f1:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-19T14:32:00.847509Z","iopub.execute_input":"2024-09-19T14:32:00.847976Z","iopub.status.idle":"2024-09-19T14:32:00.855449Z","shell.execute_reply.started":"2024-09-19T14:32:00.847929Z","shell.execute_reply":"2024-09-19T14:32:00.854201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate_unsupervised(X, y, y_pred):\n    silhouette_avg = silhouette_score(X, y_pred)\n    homogeneity = homogeneity_score(y, y_pred)\n    v_measure = v_measure_score(y, y_pred)\n    ari = adjusted_rand_score(y, y_pred)\n\n    print(f\"Silhouette Score: {silhouette_avg:.4f}\")\n    print(f\"Homogeneity Score: {homogeneity:.4f}\")\n    print(f\"V-Measure Score: {v_measure:.4f}\")\n    print(f\"Adjusted Rand Index: {ari:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-19T14:32:00.856932Z","iopub.execute_input":"2024-09-19T14:32:00.857724Z","iopub.status.idle":"2024-09-19T14:32:00.869051Z","shell.execute_reply.started":"2024-09-19T14:32:00.857676Z","shell.execute_reply":"2024-09-19T14:32:00.867665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_confusion_matrix(y_true, y_pred, labels=label_encoder.classes_):\n    # Generate the confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    \n    # Plot the confusion matrix\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n    plt.xlabel('Predicted Label')\n    plt.ylabel('True Label')\n    plt.title('Confusion Matrix')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-19T14:32:00.870727Z","iopub.execute_input":"2024-09-19T14:32:00.871227Z","iopub.status.idle":"2024-09-19T14:32:00.882774Z","shell.execute_reply.started":"2024-09-19T14:32:00.871182Z","shell.execute_reply":"2024-09-19T14:32:00.881365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluation for Random Forest\nprint(f\"Evaluation Metrices and Confusion Matrix for Random Forest\")\nevaluate(y_test, y_pred_rf)\nplot_confusion_matrix(y_test, y_pred_rf, labels=label_encoder.classes_)\n\n# Evaluation for CNN\nprint(f\"Evaluation Metrices and Confusion Matrix for CNN\")\nevaluate(y_test, y_pred_cnn)\nplot_confusion_matrix(y_test, y_pred_cnn, labels=label_encoder.classes_)\n\n# Evaluation for K-means\nprint(f\"Evaluation Metrices and Confusion Matrix for K-means\")\n##evaluate(y_test, y_pred_km_test)\nprint(f\" \")\nevaluate_unsupervised(X_pca, y_int, y_pred_km)\n##plot_confusion_matrix(y_test, y_pred_km_test, labels=label_encoder.classes_)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-19T14:32:00.884372Z","iopub.execute_input":"2024-09-19T14:32:00.885413Z","iopub.status.idle":"2024-09-19T14:32:02.529649Z","shell.execute_reply.started":"2024-09-19T14:32:00.885367Z","shell.execute_reply":"2024-09-19T14:32:02.528527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The results:\n\n1. **CNN (Convolutional Neural Network)**\n   - The CNN model demonstrates the best performance among the three algorithms. It shows strong accuracy, precision, recall, and F1 score, indicating effective classification of flower images. CNNs excel in image-related tasks due to their capability to automatically learn and extract features from images, leading to more accurate and balanced classification.\n\n2. **Random Forest**\n   - The Random Forest model exhibits moderate performance. While it achieves reasonable precision and recall, its overall accuracy and F1 score are lower than those of the CNN. This suggests that while Random Forest captures some patterns in the data, it does not perform as well in distinguishing between different flower classes compared to the CNN.\n\n3. **K-Means Clustering**\n   - K-Means clustering performs the least effectively for this classification task. It shows poor accuracy indicating significant challenges in classifying flower images. Additionally, the clustering evaluation metrics highlight issues with cluster cohesion and separation, and poor alignment with the true labels.\n\n**Summary**: \nThe CNN model is the most effective for flower classification, providing the highest accuracy and balanced performance across various metrics. Random Forest offers moderate performance but falls short compared to CNN. K-Means, being an unsupervised clustering method, struggles considerably in this classification context, as reflected by its clustering evaluation metrics.\n","metadata":{}}]}